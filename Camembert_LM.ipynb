{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Camembert_LM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1LNTR3ennJhVPkRkuADWqthbQMYiC8sGK",
      "authorship_tag": "ABX9TyNNoOsW4pTREihUR5J5yGW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/fastai2-v4/blob/master/Camembert_LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKWtHnZ_yZ_L"
      },
      "source": [
        "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6UAMPRiyuJ1"
      },
      "source": [
        "!pip install -Uq transformers\n",
        "from fastai.text.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyGyTlgiyffc"
      },
      "source": [
        "# # better display of review text in dataframes\n",
        "# pd.set_option('display.max_colwidth', None) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTSr1tC1Pfz3"
      },
      "source": [
        "# CamentBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x46GqlW1PnT9",
        "outputId": "bc6b1ebe-2a66-438b-b4ce-6726b6c09b9f"
      },
      "source": [
        "!pip install sentencepiece\n",
        "\n",
        "from transformers import CamembertTokenizer, CamembertForCausalLM\n",
        "\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "#model = CamembertForCausalLM.from_pretrained(\"camembert-base\")\n",
        "#model = CamembertForCausalLM.from_pretrained(\"camembert-base\", is_decoder=True)\n",
        "model = CamembertForCausalLM.from_pretrained(\"camembert-base\", is_decoder=True, add_cross_attention=True)\n",
        "\n",
        "#transformers.RobertaForCausalLM.from_pretrained(pretrained_model_name_or_path='roberta-base', add_cross_attention=True, is_decoder=True, bos_token_id=<bos-id>, eos_token_id=<eos-id>)?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForCausalLM were not initialized from the model checkpoint at camembert-base and are newly initialized: ['roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ccrve8Y1JZa"
      },
      "source": [
        "NOTE: Language Modeling\n",
        "- **Causal language modeling**: the model has to predict the next token in the sentence (so the labels are the same as the inputs shifted to the right). To make sure the model does not cheat, it gets an attention mask that will prevent it to access the tokens after token i when trying to predict the token i+1 in the sentence.\n",
        "- **Masked language modeling**: the model has to predict some tokens that are masked in the input. It still has access to the whole sentence, so it can use the tokens before and after the tokens masked to predict their value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy4ErxC3Rs-N",
        "outputId": "6d3e79af-b0f3-45ee-b1bb-359eaa4f010f"
      },
      "source": [
        "ids = tokenizer.encode('Ce texte est affligeant, et')\n",
        "ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 148, 930, 30, 5639, 1187, 17059, 7, 14, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaSd7tfiXbQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3f2077-b67d-4684-c0af-f7e6bf8a1eaf"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CamembertForCausalLM(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): RobertaLMHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (decoder): Linear(in_features=768, out_features=32005, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EHpLcwrzAyu"
      },
      "source": [
        "# Getting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKpWrK3onkIS",
        "outputId": "624d1aeb-d461-4816-ea00-88d7de90583f"
      },
      "source": [
        "# Download repo and its dependencies \n",
        "!git clone https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/\n",
        "!cd french-sentiment-analysis-with-bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'french-sentiment-analysis-with-bert' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxhx5QpdJgRF",
        "outputId": "fe8502d6-64a2-4b44-aee4-dfbc5deabdcd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  french-sentiment-analysis-with-bert  models  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc7K8gusoStx"
      },
      "source": [
        "!tar -xf /content/french-sentiment-analysis-with-bert/allocine_dataset/data.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkXTUXtipNVe",
        "outputId": "67893d59-6904-493e-ceca-1bc519f2e2e0"
      },
      "source": [
        "!cd data; ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allocine_dataset.pickle\t\t\t test.jsonl  train.jsonl  val.jsonl\n",
            "camembert_vocab-sentencepiece.bpe.model  train.csv   val.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ovxly8oCihb"
      },
      "source": [
        "## Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "PK3M8koupmPl",
        "outputId": "307f35cb-4875-4b6c-8f47-5f1da3ec8560"
      },
      "source": [
        "train_df = pd.read_json('/content/data/train.jsonl', lines=True, nrows=600)\n",
        "train_df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>film-url</th>\n",
              "      <th>review</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-135259/critiques/spectateurs</td>\n",
              "      <td>Si vous cherchez du cinéma abrutissant à tous les étages,n'ayant aucune peur du cliché en castagnettes et moralement douteux,\"From Paris with love\" est fait pour vous.Toutes les productions Besson,via sa filière EuropaCorp ont de quoi faire naître la moquerie.Paris y est encore une fois montrée comme une capitale exotique,mais attention si l'on se dirige vers la banlieue,on y trouve tout plein d'intégristes musulmans prêts à faire sauter le caisson d'une ambassadrice américaine.Nauséeux.Alors on se dit qu'on va au moins pouvoir apprécier la déconnade d'un classique buddy-movie avec le jeun...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             film-url  ... polarity\n",
              "0  http://www.allocine.fr/film/fichefilm-135259/critiques/spectateurs  ...        0\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQLCm9IJM0fX",
        "outputId": "071d0524-4383-45d7-c22d-e056fcd38850"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "gLQHnNXDMETP",
        "outputId": "ff4d8b16-b16a-4c8f-d526-7494201fd58b"
      },
      "source": [
        "some_review = train_df.review[0]; some_review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Si vous cherchez du cinéma abrutissant à tous les étages,n\\'ayant aucune peur du cliché en castagnettes et moralement douteux,\"From Paris with love\" est fait pour vous.Toutes les productions Besson,via sa filière EuropaCorp ont de quoi faire naître la moquerie.Paris y est encore une fois montrée comme une capitale exotique,mais attention si l\\'on se dirige vers la banlieue,on y trouve tout plein d\\'intégristes musulmans prêts à faire sauter le caisson d\\'une ambassadrice américaine.Nauséeux.Alors on se dit qu\\'on va au moins pouvoir apprécier la déconnade d\\'un classique buddy-movie avec le jeune agent aux dents longues obligé de faire équipe avec un vieux lou complètement timbré.Mais d\\'un côté,on a un Jonathan Rhys-meyers fayot au possible,et de l\\'autre un John Travolta en total délire narcissico-badass,crâne rasé et bouc proéminent à l\\'appui.Sinon,il n\\'y a aucun scénario.Seulement,des poursuites débiles sur l\\'autoroute,Travolta qui étale 10 mecs à l\\'arme blanche en 8 mouvements(!!)ou laisse son associé se faire démolir la tronche pendant qu\\'il scrute à la jumelle.Ca pourrait être un plaisir coupable,tellement c\\'est \"hénaurme\",c\\'est juste de la daube dans la droite lignée d\\'un \"Transporteur\",\"Taken\"ou \"Banlieue 13\".'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoN_ZNoXKi7j",
        "outputId": "6af7a898-830a-42fe-bb0a-33315134e315"
      },
      "source": [
        "tokenizer.tokenize(some_review)[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁Si',\n",
              " '▁vous',\n",
              " '▁cherchez',\n",
              " '▁du',\n",
              " '▁cinéma',\n",
              " '▁abruti',\n",
              " 'ssant',\n",
              " '▁à',\n",
              " '▁tous',\n",
              " '▁les',\n",
              " '▁étages',\n",
              " ',',\n",
              " 'n',\n",
              " \"'\",\n",
              " 'ayant']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ku0ouxlKrbW",
        "outputId": "02fe48de-5203-4d64-f77f-07fea7204891"
      },
      "source": [
        "tokenizer.encode(some_review)[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 168, 39, 3162, 25, 1545, 29470, 2927, 15, 117, 19, 9339, 7, 255, 11]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "2hm1OyK7K3cR",
        "outputId": "36a72d95-3038-4c7d-c10a-6a630e9f40d1"
      },
      "source": [
        "tokenizer.decode(tokenizer.encode(some_review))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s> Si vous cherchez du cinéma abrutissant à tous les étages,n\\'ayant aucune peur du cliché en castagnettes et moralement douteux,\"From Paris with love\" est fait pour vous.Toutes les productions Besson,via sa filière EuropaCorp ont de quoi faire naître la moquerie.Paris y est encore une fois montrée comme une capitale exotique,mais attention si l\\'on se dirige vers la banlieue,on y trouve tout plein d\\'intégristes musulmans prêts à faire sauter le caisson d\\'une ambassadrice américaine.Nauséeux.Alors on se dit qu\\'on va au moins pouvoir apprécier la déconnade d\\'un classique buddy-movie avec le jeune agent aux dents longues obligé de faire équipe avec un vieux lou complètement timbré.Mais d\\'un côté,on a un Jonathan Rhys-meyers fayot au possible,et de l\\'autre un John Travolta en total délire narcissico-badass,crâne rasé et bouc proéminent à l\\'appui.Sinon,il n\\'y a aucun scénario.Seulement,des poursuites débiles sur l\\'autoroute,Travolta qui étale 10 mecs à l\\'arme blanche en 8 mouvements(!!)ou laisse son associé se faire démolir la tronche pendant qu\\'il scrute à la jumelle.Ca pourrait être un plaisir coupable,tellement c\\'est \"hénaurme\",c\\'est juste de la daube dans la droite lignée d\\'un \"Transporteur\",\"Taken\"ou \"Banlieue 13\".</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWte_UZzKGex"
      },
      "source": [
        "train_df.to_csv('/content/data/train.csv', encoding = 'utf-8', header = False, index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xpott7ZHNbP"
      },
      "source": [
        "df_train = pd.read_csv('/content/data/train.csv', encoding = 'utf-8', header=None)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSoDnHfeIRGK"
      },
      "source": [
        "# !cp /content/data/train.csv /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0YOts2pF_zu"
      },
      "source": [
        "## Validation DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "arkJO-pms20p",
        "outputId": "3b41288e-3228-457a-f76f-db9fede8039c"
      },
      "source": [
        "val_df = pd.read_json('/content/data/val.jsonl', lines=True, nrows=200)\n",
        "val_df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>film-url</th>\n",
              "      <th>review</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-51895/critiques/spectateurs</td>\n",
              "      <td>Ce film est tout ce qu'il y a de plus sympa. Même si l'ensemble n'est pas dépourvu de clichés, il serait hypocrite de dire que ce film est ennuyeux à regarder, bien au contraire. Il est très plaisant à regarder et même si l'ensemble est asse convenue, la mise en scène de Peter Chelsom est légère et ce film est une sorte de bouffée d'air frais. Tout à fait estimable.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                            film-url  ... polarity\n",
              "0  http://www.allocine.fr/film/fichefilm-51895/critiques/spectateurs  ...        0\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qKDUZCHDlFf",
        "outputId": "4ac637e8-c8ae-41cc-bff2-17adc905286f"
      },
      "source": [
        "val_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMKW7fjFKkYD"
      },
      "source": [
        "val_df.to_csv('/content/data/val.csv', encoding = 'utf-8', header = False, index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbI4W-PeHazq"
      },
      "source": [
        "df_valid = pd.read_csv('/content/data/val.csv', encoding = 'utf-8', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4xFff34IIjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7777e97-e780-47b7-900a-e353ed10fab6"
      },
      "source": [
        "!cp /content/data/val.csv /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot create regular file '/content/drive/MyDrive': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwCe3cXuHc8f"
      },
      "source": [
        "## All Texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uHwYE0zzjxr"
      },
      "source": [
        "all_texts = np.concatenate([df_train[1].values, df_valid[1].values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8CkhyOVtkXp"
      },
      "source": [
        "# print(train_df['polarity'].unique(), val_df['polarity'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEVEHjmqHsJ3"
      },
      "source": [
        "NOTE: polarity: `0` negative review; `1` positive review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOq40ZE21D-D",
        "outputId": "23d6b848-3333-4702-ef4f-3dc315815807"
      },
      "source": [
        "print(len(train_df), len(val_df), len(all_texts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600 200 800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHhoJLy19eD5"
      },
      "source": [
        "class TransformersTokenizer(Transform):\n",
        "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
        "    def encodes(self, x): \n",
        "        toks = self.tokenizer.tokenize(x)\n",
        "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
        "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cULmRoiNBGgO"
      },
      "source": [
        "splits = [range_of(df_train), list(range(len(df_train), len(all_texts)))]\n",
        "tls = TfmdLists(all_texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6pQ3x-eFEjt"
      },
      "source": [
        "# tls.train[0],tls.valid[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBuYztgLFFFV",
        "outputId": "b128ae8d-ace4-4f91-fc62-1ee927b7f23e"
      },
      "source": [
        "tls.tfms(tls.train.items[0]).shape, tls.tfms(tls.valid.items[0]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([332]), torch.Size([93]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YptWWuQ-FJk0",
        "outputId": "305ba2b3-a792-4d92-9851-4620a8169719"
      },
      "source": [
        "show_at(tls.train, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Si vous cherchez du cinéma abrutissant à tous les étages,n'ayant aucune peur du cliché en castagnettes et moralement douteux,\"From Paris with love\" est fait pour vous.Toutes les productions Besson,via sa filière EuropaCorp ont de quoi faire naître la moquerie.Paris y est encore une fois montrée comme une capitale exotique,mais attention si l'on se dirige vers la banlieue,on y trouve tout plein d'intégristes musulmans prêts à faire sauter le caisson d'une ambassadrice américaine.Nauséeux.Alors on se dit qu'on va au moins pouvoir apprécier la déconnade d'un classique buddy-movie avec le jeune agent aux dents longues obligé de faire équipe avec un vieux lou complètement timbré.Mais d'un côté,on a un Jonathan Rhys-meyers fayot au possible,et de l'autre un John Travolta en total délire narcissico-badass,crâne rasé et bouc proéminent à l'appui.Sinon,il n'y a aucun scénario.Seulement,des poursuites débiles sur l'autoroute,Travolta qui étale 10 mecs à l'arme blanche en 8 mouvements(!!)ou laisse son associé se faire démolir la tronche pendant qu'il scrute à la jumelle.Ca pourrait être un plaisir coupable,tellement c'est \"hénaurme\",c'est juste de la daube dans la droite lignée d'un \"Transporteur\",\"Taken\"ou \"Banlieue 13\".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Asa8qVtFPNQ",
        "outputId": "4e76a1b9-8daf-4e5c-bc82-fde9f5091618"
      },
      "source": [
        "show_at(tls.valid, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ce film est tout ce qu'il y a de plus sympa. Même si l'ensemble n'est pas dépourvu de clichés, il serait hypocrite de dire que ce film est ennuyeux à regarder, bien au contraire. Il est très plaisant à regarder et même si l'ensemble est asse convenue, la mise en scène de Peter Chelsom est légère et ce film est une sorte de bouffée d'air frais. Tout à fait estimable.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7SDVlrpxCs4"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUw-rnwJFVli"
      },
      "source": [
        "#bs,sl = 4,256 # not working\n",
        "bs,sl = 4, 256\n",
        "dls_lm = tls.dataloaders(bs=bs, seq_len=sl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "XCDFnruRFaR6",
        "outputId": "f541a4f8-65b0-4c10-e212-40386c536825"
      },
      "source": [
        "dls_lm.show_batch(max_n=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Malgré un background quelque peu naif - certains ont dit racoleur - ; il s'agit toute de même d'un bon report sur la shoa &amp; une belle preuve de cette énorme organisation nazie formant le coeur de l'horreur de cette guerre, &amp; dont bien sûr le SA décrit tel Goeth dans \" La liste de Schindler \" n'en est bien sûr que le représentant... Un très bon petit film noir, certes classique dans l'histoire, mais rudement efficace niveau mise en scène. Frankenheimer à la recherche de nouveauté s'essaye à un mélange de style franco, anglais sur le thème de la crise du couple en y ajoutant une dose d'imagination d'écrivain. Le partie française n'est vraiment pas une réussite avec des acteurs qui récitent leurs textes et le coté imaginaire n'est pas d'un grand intérêt. Le réalisateur propose tout de même une scène un peu technique avec une barque pris dans</td>\n",
              "      <td>un background quelque peu naif - certains ont dit racoleur - ; il s'agit toute de même d'un bon report sur la shoa &amp; une belle preuve de cette énorme organisation nazie formant le coeur de l'horreur de cette guerre, &amp; dont bien sûr le SA décrit tel Goeth dans \" La liste de Schindler \" n'en est bien sûr que le représentant... Un très bon petit film noir, certes classique dans l'histoire, mais rudement efficace niveau mise en scène. Frankenheimer à la recherche de nouveauté s'essaye à un mélange de style franco, anglais sur le thème de la crise du couple en y ajoutant une dose d'imagination d'écrivain. Le partie française n'est vraiment pas une réussite avec des acteurs qui récitent leurs textes et le coté imaginaire n'est pas d'un grand intérêt. Le réalisateur propose tout de même une scène un peu technique avec une barque pris dans les</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ne me gène pas, il y a certains films qui réussissent à faire des perles dans ce genre, mais au fond de cette soupe d'idées juxtaposées jusqu'à la nausée... Il n'y a pas de moralité, normal ce film veut se faire immoral... Mais après lecture totale, il n'y a pas d'immoralité... Il y a rien du tout... Je reste con... Je n'aime pas. Lorsqu'Irène Foster arrive à Broadway, elle espère qu'une de ses connaissances, devenu producteur, l'aidera à monter sur les planches, malheureusement pour elle, et dans un premier temps, il ne la reconnaîtra pas... Comédie musicale typique des années de la grande dépression, Broadway Melody of 1936 permit aussi à la MGM de se maintenir à flot et nous immerge dans le monde de Broadway avec ses planches, sa gloire, ses danseurs et chanteurs. Alors que la série avait commencé en 1929, Roy Del Ruth lui fait vraiment prendre</td>\n",
              "      <td>me gène pas, il y a certains films qui réussissent à faire des perles dans ce genre, mais au fond de cette soupe d'idées juxtaposées jusqu'à la nausée... Il n'y a pas de moralité, normal ce film veut se faire immoral... Mais après lecture totale, il n'y a pas d'immoralité... Il y a rien du tout... Je reste con... Je n'aime pas. Lorsqu'Irène Foster arrive à Broadway, elle espère qu'une de ses connaissances, devenu producteur, l'aidera à monter sur les planches, malheureusement pour elle, et dans un premier temps, il ne la reconnaîtra pas... Comédie musicale typique des années de la grande dépression, Broadway Melody of 1936 permit aussi à la MGM de se maintenir à flot et nous immerge dans le monde de Broadway avec ses planches, sa gloire, ses danseurs et chanteurs. Alors que la série avait commencé en 1929, Roy Del Ruth lui fait vraiment prendre son</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "gBfaH1dbF5ZZ",
        "outputId": "94b45c82-7048-4f63-a1b5-14b5b6a6ee0b"
      },
      "source": [
        "def tokenize(text):\n",
        "    toks = tokenizer.tokenize(text)\n",
        "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
        "\n",
        "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='800' class='' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [800/800 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXBCICS3O2V-",
        "outputId": "c747316b-56ff-4390-ab56-dd24730b6db7"
      },
      "source": [
        "len(tokenized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr3xq1yrZ976",
        "outputId": "fd0b409a-30dd-4505-d401-18e9f3c19f6e"
      },
      "source": [
        "tokenizer.vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UAkDC6ApMIr",
        "outputId": "a629b93a-941c-4a8a-b827-7ca49b471bca"
      },
      "source": [
        "tokenizer.add_tokens('tokenized')\n",
        "#model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TOHxOHwpi5M",
        "outputId": "4b235c29-e981-45ae-d53e-91cca89cf227"
      },
      "source": [
        "tokenizer.vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ0560cUpw-2",
        "outputId": "087505f5-0479-4330-e3eb-e2ea7caf3a16"
      },
      "source": [
        "len(tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeSBJ9BYW_K9"
      },
      "source": [
        "class TransformersTokenizer(Transform):\n",
        "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
        "    def encodes(self, x): \n",
        "        return x if isinstance(x, Tensor) else tokenize(x)\n",
        "        \n",
        "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFjyv9yGxMC-"
      },
      "source": [
        "## Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiIyUrLXV4w8"
      },
      "source": [
        "class DropOutput(Callback):\n",
        "    def after_pred(self): self.learn.pred = self.pred[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH-DmjDuYmdf"
      },
      "source": [
        "# del learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGHrXq1oXUOv"
      },
      "source": [
        "learn = Learner(dls_lm, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eD19N6YZK-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df262d85-9f6f-4d64-8cd2-b363a3f4a506"
      },
      "source": [
        "learn.model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CamembertForCausalLM(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): RobertaLMHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (decoder): Linear(in_features=768, out_features=32005, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "b14X5dHxXXs1",
        "outputId": "edc615bb-0255-4a2c-e40c-ea9dc1c2d208"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [14.09053897857666,1316568.125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jELnzv2XbVF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "bc0adc5d-b2e8-44ee-a35c-572d29e4d554"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=0.02089296132326126, lr_steep=0.17378008365631104)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyMgjK7oXe-H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "3cae6a94-1c02-46dd-ef5f-1e81866dc007"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.314414</td>\n",
              "      <td>5.425480</td>\n",
              "      <td>227.120422</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EosVFJwKknhn"
      },
      "source": [
        "# saving the vocabulary\n",
        "vocab_lm = tokenizer.save_vocabulary('./data', 'camembert_vocab')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjGGXRwnZFxe",
        "outputId": "035d5da3-733a-4724-a0de-1d9e9685f70a"
      },
      "source": [
        "# saving the newly trained model\n",
        "learn.save('1epoch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/1epoch.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTP5GeZ7xQxz"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPvgRRL5XiwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "852a2345-d241-403c-f4e6-15dfd7135059"
      },
      "source": [
        "df_valid.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-51895/critiques/spectateurs</td>\n",
              "      <td>Ce film est tout ce qu'il y a de plus sympa. Même si l'ensemble n'est pas dépourvu de clichés, il serait hypocrite de dire que ce film est ennuyeux à regarder, bien au contraire. Il est très plaisant à regarder et même si l'ensemble est asse convenue, la mise en scène de Peter Chelsom est légère et ce film est une sorte de bouffée d'air frais. Tout à fait estimable.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                   0  ...  2\n",
              "0  http://www.allocine.fr/film/fichefilm-51895/critiques/spectateurs  ...  0\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqPWZnaVXmm2"
      },
      "source": [
        "prompt = \"ce film est un navet, il met en\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYphngtMXtlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5d5423-86f9-4a1c-ab11-4d4323209a96"
      },
      "source": [
        "prompt_ids = tokenizer.encode(prompt)\n",
        "inp = tensor(prompt_ids)[None].cuda()\n",
        "inp.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVo38yMPZQIb"
      },
      "source": [
        "preds = learn.model.generate(inp, max_length=40, num_beams=5, temperature=1.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJspnelfXxv7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f008a7f1-3078-4bee-eed6-b35255fa82e6"
      },
      "source": [
        "tokenizer.decode(preds[0].cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s> ce film est un navet, il met en</s> scène une une scène de de guerre guerre de la fin de de la guerre guerre de la la guerre guerre de la la guerre guerre de la'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VINNayH8hVXR"
      },
      "source": [
        "NOTE: The model 'RobertaForCausalLM' is not supported for text-generation. Supported models are ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'GPTNeoForCausalLM', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RK5dvGt9SYh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}